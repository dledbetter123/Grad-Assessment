{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "s2l1kFXg_uwn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc2b7296-8c58-41e1-d4f7-39f1cf08f14b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "Wanh1AtQ_okG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2d6ae1f-fd16-4849-efdd-73bd781b289b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/drive/MyDrive/GradAssessment && ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vc3tqrb_24N",
        "outputId": "a204cfa2-e7cb-4e8b-a576-1fa3877a7c0d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'10362-Article Text-13890-1-2-20201228.pdf'   layers.py        Model.ipynb   test.txt\t valid.txt\n",
            " GA_Writeup.pdf\t\t\t\t      Model_ex.ipynb   README.md     train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lpV3wVP8_Pxl",
        "outputId": "baf3e9c5-4e7d-452e-fcee-1cc73703cd39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAAZCCqFCvJj",
        "outputId": "bf0ebf6e-a6be-4a4a-848c-ec145b044033"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Collecting torch\n",
            "  Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "9kZH2RNeBCHv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j81PE3ks_Pxn"
      },
      "source": [
        "# Deprecated Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0lPZKUMN_Pxo",
        "outputId": "e147662f-0f9b-4746-9ade-67cb85abd8c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<pad>': 0, '<unk>': 1, ' ': 2, 'H': 3, 'T': 4, 'a': 5, 'c': 6, 'd': 7, 'e': 8, 'h': 9, 'i': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'r': 16, 's': 17, 't': 18, 'w': 19, 'x': 20}\n",
            "{'<pad>': 0, '<unk>': 1, 'world': 2, 'an': 3, 'sentence': 4, 'is': 5, 'Hello': 6, 'This': 7, 'example': 8}\n"
          ]
        }
      ],
      "source": [
        "# new way to tokenize\n",
        "def build_char_vocab(corpus):\n",
        "    char_set = set()\n",
        "    for sentence in corpus:\n",
        "        char_set.update(sentence)\n",
        "    # <pad> and <unk>\n",
        "    char_vocab = {'<pad>': 0, '<unk>': 1}\n",
        "    char_vocab.update({char: idx + 2 for idx, char in enumerate(sorted(char_set))})\n",
        "    return char_vocab\n",
        "\n",
        "corpus = [\"Hello world\", \"This is an example sentence\"]\n",
        "char_vocab = build_char_vocab(corpus)\n",
        "print(char_vocab)\n",
        "\n",
        "def build_word_vocab(corpus):\n",
        "    word_set = set()\n",
        "    for sentence in corpus:\n",
        "        word_set.update(sentence.split())\n",
        "    # adding <pad> and <unk>\n",
        "    word_vocab = {'<pad>': 0, '<unk>': 1} # gonna assume it doesn't need to be sorted, read that we don't need it rn.\n",
        "    word_vocab.update({word: idx + 2 for idx, word in enumerate(word_set)})\n",
        "    return word_vocab\n",
        "\n",
        "corpus = [\"Hello world\", \"This is an example sentence\"]\n",
        "word_vocab = build_word_vocab(corpus)\n",
        "print(word_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pWbEMssi_Pxp",
        "outputId": "4fa5098e-cd9a-494b-f7a2-df240936acf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 9,  8, 11, 11, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [19, 14, 16, 11,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [18,  9, 10, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [10, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 5, 13,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 8, 20,  5, 12, 15, 11,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [17,  8, 13, 18,  8, 13,  6,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n"
          ]
        }
      ],
      "source": [
        "# def one_hot_encode(index, vocab_size):\n",
        "#     one_hot = torch.zeros(vocab_size)\n",
        "#     one_hot[index] = 1\n",
        "#     return one_hot\n",
        "\n",
        "# def preprocess_corpus(corpus, char_vocab, max_length):\n",
        "#     vocab_size = len(char_vocab)\n",
        "#     processed_corpus = []\n",
        "#     for sentence in corpus:\n",
        "#         sentence_indices = [char_vocab.get(char, char_vocab['<unk>']) for char in sentence.lower()]\n",
        "#         padded_indices = sentence_indices + [char_vocab['<pad>']] * (max_length - len(sentence_indices))\n",
        "#         # one_hot_sentence = [one_hot_encode(index, vocab_size) for index in padded_indices[:max_length]]\n",
        "#         processed_corpus.append(torch.stack(one_hot_sentence))\n",
        "#     return torch.stack(processed_corpus)\n",
        "\n",
        "def preprocess_corpus(corpus, char_vocab, max_length=30):\n",
        "        processed_corpus = []\n",
        "    for sentence in corpus:\n",
        "        words = sentence.split()  # Splitting the sentence into words\n",
        "        for word in words:\n",
        "            word_indices = [char_vocab.get(char, char_vocab['<unk>']) for char in word.lower()]\n",
        "            # Pad each word to max_length\n",
        "            padded_indices = word_indices + [char_vocab['<pad>']] * (max_length - len(word_indices))\n",
        "            processed_corpus.append(padded_indices[:max_length])\n",
        "    return processed_corpus\n",
        "\n",
        "corpus = [\"Hello world\", \"This is an example sentence\"]\n",
        "\n",
        "processed_corpus = preprocess_corpus(corpus, char_vocab)\n",
        "\n",
        "input_tensor = torch.tensor(processed_corpus)\n",
        "print(input_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWD2myWx_Pxp"
      },
      "source": [
        "# Active Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WN0M98F2_Pxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785c3f0e-f27f-4287-d236-fe11433e6f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class HighwayBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.project = nn.Linear(input_dim, output_dim)\n",
        "        self.transform = nn.Linear(input_dim, output_dim)\n",
        "        self.trans_bias = nn.Parameter(torch.tensor(-2.0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        proj_output = torch.relu(self.project(x))\n",
        "        trans_output = torch.sigmoid(self.transform(x) + self.trans_bias)\n",
        "        return trans_output * proj_output + (1 - trans_output) * x\n",
        "\n",
        "class HighwayNetwork(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_layers):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.layers = []\n",
        "        for i in range(num_layers):\n",
        "            layer_size = input_size if i == 0 else output_size\n",
        "            self.layers.append(HighwayBlock(layer_size, output_size))\n",
        "            self.add_module(f'highway_block_{i}', self.layers[-1])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "class ConvolutionBlock(nn.Module):\n",
        "    def __init__(self, channels, kernel, features):\n",
        "        super().__init__()\n",
        "        self.conv_layer = nn.Conv2d(channels, features, kernel)\n",
        "\n",
        "    def forward(self, x, size_reduce):\n",
        "        conv_output = torch.tanh(self.conv_layer(x))\n",
        "        pooled_output = F.max_pool2d(conv_output, kernel_size=[1, size_reduce])\n",
        "        return pooled_output.squeeze(3).squeeze(2)\n",
        "\n",
        "class ConvolutionNetwork(nn.Module):\n",
        "    def __init__(self, channel_size, kernel_sizes, feature_sizes):\n",
        "        super().__init__()\n",
        "        self.conv_blocks = nn.ModuleList()\n",
        "\n",
        "        # applies the filters of differenent widths over input\n",
        "        for i, (k_size, f_size) in enumerate(zip(kernel_sizes, feature_sizes)):\n",
        "            self.conv_blocks.append(ConvolutionBlock(channel_size, (1, k_size), f_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # squeezes output to accomodate for batches\n",
        "        x = x.unsqueeze(2).transpose(1, 3)\n",
        "        conv_outputs = [block(x, x.size(3) - k_size + 1) for block, k_size in zip(self.conv_blocks, kernel_sizes)]\n",
        "        return torch.cat(conv_outputs, 1)\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate):\n",
        "        super().__init__()\n",
        "        self.rnn_layers = nn.LSTM(input_size, hidden_size, num_layers=num_layers, dropout=dropout_rate)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    # use this instead of hidden state init outside\n",
        "    def init_hidden_state(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size),\n",
        "                torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        output, hidden = self.rnn_layers(x, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "class CharacterToWordModel(nn.Module):\n",
        "    def __init__(self, char_vocab_size, char_embed_dim, word_vocab_size,\n",
        "                 conv_out_size, hidden_dim, kernel_sizes, features, num_highway_layers,\n",
        "                 num_rnn_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.char_vocab_size = char_vocab_size\n",
        "        self.char_embed_dim = char_embed_dim\n",
        "        self.word_vocab_size = word_vocab_size\n",
        "        self.conv_out_size = conv_out_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout_rate = dropout\n",
        "\n",
        "        self.char_embedding = nn.Embedding(char_vocab_size, char_embed_dim, padding_idx=0)\n",
        "        # print(\"charvocab\", char_vocab_size, \"char_embed_dim\", char_embed_dim)\n",
        "        self.conv_net = ConvolutionNetwork(char_embed_dim, kernel_sizes, features)\n",
        "        self.highway_net = HighwayNetwork(conv_out_size, conv_out_size, num_highway_layers)\n",
        "        self.rnn_net = RNN(conv_out_size, hidden_dim, num_rnn_layers, dropout)\n",
        "        self.output_layer = nn.Linear(hidden_dim, word_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.initw()\n",
        "\n",
        "    def initw(self):\n",
        "        rng = 0.1\n",
        "        self.char_embedding.weight.data.uniform_(-rng, rng)\n",
        "        self.output_layer.bias.data.fill_(0)\n",
        "        self.output_layer.weight.data.uniform_(-rng, rng)\n",
        "\n",
        "    def forward(self, input_chars, hidden_state):\n",
        "        # print(\"input shape\", input_chars.shape)\n",
        "        emb = self.char_embedding(input_chars)\n",
        "        # print(\"embedding shape\", emb.shape)\n",
        "        conv_output = self.conv_net(emb)\n",
        "        highway_output = self.highway_net(conv_output)\n",
        "        rnn_output, hidden_state = self.rnn_net(highway_output, hidden_state)\n",
        "        rnn_output = self.dropout(rnn_output)\n",
        "        final_output = self.output_layer(rnn_output.view(-1, self.hidden_dim))\n",
        "        top_word_indices = torch.argmax(final_output, dim=-1)\n",
        "        return final_output, hidden_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FNhkyc-v_Pxq",
        "outputId": "cd6b9d3b-d8ab-494c-f5e8-58bf5af2f7d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Directory: /content/drive/MyDrive/GradAssessment\n",
            "18\n",
            "['Hello world', 'This is an example sentence', 'To be or not to be, that is the question', 'I think, therefore I am']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "path = '/content/drive/MyDrive/GradAssessment'\n",
        "os.chdir(path)\n",
        "print(\"Current Directory:\", os.getcwd())\n",
        "\n",
        "def load_dataset(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = file.readlines()\n",
        "    return data\n",
        "\n",
        "train_data = load_dataset('train.txt')\n",
        "valid_data = load_dataset('valid.txt')\n",
        "test_data = load_dataset('test.txt')\n",
        "\n",
        "def preprocess_data(data):\n",
        "    corpus = []\n",
        "    for sentence in data:\n",
        "        words = sentence.strip().split()\n",
        "        for i in range(len(words) - 1):\n",
        "            predictor = words[i]\n",
        "            target = words[i + 1]\n",
        "            corpus.append((predictor, target))\n",
        "    return corpus\n",
        "testing = [\n",
        "    \"Hello world\",\n",
        "    \"This is an example sentence\",\n",
        "    \"To be or not to be, that is the question\",\n",
        "    \"I think, therefore I am\",]\n",
        "\n",
        "test = preprocess_data(testing)\n",
        "print(len(test))\n",
        "print(testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xyaVDpF9_Pxq",
        "outputId": "cbe00cca-fbc6-4e1a-fbb0-602b529012c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kegeAG44_Pxq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# def data_to_tensors(corpus, char_vocab, word_vocab):\n",
        "#     predictors = []\n",
        "#     targets = []\n",
        "#     for predictor, target in corpus:\n",
        "#         predictor_indices = [char_vocab.get(char, char_vocab['<unk>']) for char in predictor]\n",
        "#         # print(predictors)\n",
        "#         target_index = word_vocab.get(target, word_vocab['<unk>'])\n",
        "#         predictors.append(predictor_indices)\n",
        "#         targets.append(target_index)\n",
        "#     print(len(predictors))\n",
        "#     print(len(targets))\n",
        "#     return torch.tensor(predictors), torch.tensor(targets)\n",
        "\n",
        "# train_predictors, train_targets = data_to_tensors(train_corpus, char_vocab, word_vocab)\n",
        "# valid_predictors, valid_targets = data_to_tensors(valid_corpus, char_vocab, word_vocab)\n",
        "# test_predictors, test_targets = data_to_tensors(test_corpus, char_vocab, word_vocab)\n",
        "\n",
        "def data_to_tensors(corpus, char_vocab, word_vocab, max_sequence_length):\n",
        "    predictors = []\n",
        "    targets = []\n",
        "\n",
        "    for predictor, target in corpus:\n",
        "        predictor_indices = [char_vocab.get(char, char_vocab['<unk>']) for char in predictor]\n",
        "        target_index = word_vocab.get(target, word_vocab['<unk>'])\n",
        "        if (target_index == 9999):\n",
        "            print(\"index 9999: \", target)\n",
        "        if (target_index == 10000):\n",
        "            print(\"index 10000: \", target)\n",
        "        # Pad the predictor sequence\n",
        "        if len(predictor_indices) < max_sequence_length:\n",
        "            predictor_indices += [char_vocab['<pad>']] * (max_sequence_length - len(predictor_indices))\n",
        "        else:\n",
        "            predictor_indices = predictor_indices[:max_sequence_length]\n",
        "\n",
        "        predictors.append(predictor_indices)\n",
        "        targets.append(target_index)\n",
        "\n",
        "    return torch.tensor(predictors), torch.tensor(targets)\n",
        "\n",
        "# train_predictors, train_targets = data_to_tensors(train_corpus, char_vocab, word_vocab, max_sequence_length)\n",
        "# valid_predictors, valid_targets = data_to_tensors(valid_corpus, char_vocab, word_vocab, max_sequence_length)\n",
        "# test_predictors, test_targets = data_to_tensors(test_corpus, char_vocab, word_vocab, max_sequence_length)\n",
        "\n",
        "# batch_size = 20\n",
        "# train_dataset = TensorDataset(train_predictors, train_targets)\n",
        "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sMh7vyXd_Pxq",
        "outputId": "87c357e5-a931-44cb-ee76-5b6bb1902ad3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique words not presets: 9998\n",
            "Total unique words including <pad> and <unk>: 9999\n",
            "word vocab size: 9999\n",
            "char_embedding.weight torch.float32\n",
            "conv_net.conv_blocks.0.conv_layer.weight torch.float32\n",
            "conv_net.conv_blocks.0.conv_layer.bias torch.float32\n",
            "conv_net.conv_blocks.1.conv_layer.weight torch.float32\n",
            "conv_net.conv_blocks.1.conv_layer.bias torch.float32\n",
            "conv_net.conv_blocks.2.conv_layer.weight torch.float32\n",
            "conv_net.conv_blocks.2.conv_layer.bias torch.float32\n",
            "conv_net.conv_blocks.3.conv_layer.weight torch.float32\n",
            "conv_net.conv_blocks.3.conv_layer.bias torch.float32\n",
            "highway_net.highway_block_0.trans_bias torch.float32\n",
            "highway_net.highway_block_0.project.weight torch.float32\n",
            "highway_net.highway_block_0.project.bias torch.float32\n",
            "highway_net.highway_block_0.transform.weight torch.float32\n",
            "highway_net.highway_block_0.transform.bias torch.float32\n",
            "highway_net.highway_block_1.trans_bias torch.float32\n",
            "highway_net.highway_block_1.project.weight torch.float32\n",
            "highway_net.highway_block_1.project.bias torch.float32\n",
            "highway_net.highway_block_1.transform.weight torch.float32\n",
            "highway_net.highway_block_1.transform.bias torch.float32\n",
            "rnn_net.rnn_layers.weight_ih_l0 torch.float32\n",
            "rnn_net.rnn_layers.weight_hh_l0 torch.float32\n",
            "rnn_net.rnn_layers.bias_ih_l0 torch.float32\n",
            "rnn_net.rnn_layers.bias_hh_l0 torch.float32\n",
            "rnn_net.rnn_layers.weight_ih_l1 torch.float32\n",
            "rnn_net.rnn_layers.weight_hh_l1 torch.float32\n",
            "rnn_net.rnn_layers.bias_ih_l1 torch.float32\n",
            "rnn_net.rnn_layers.bias_hh_l1 torch.float32\n",
            "output_layer.weight torch.float32\n",
            "output_layer.bias torch.float32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.83it/s, accuracy=11.28%, loss=0.0242]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 completed. Loss: 0.0242, Accuracy: 11.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100: 100%|██████████| 3303/3303 [03:04<00:00, 17.88it/s, accuracy=14.27%, loss=0.0226]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 completed. Loss: 0.0226, Accuracy: 14.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.78it/s, accuracy=15.23%, loss=0.0219]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 completed. Loss: 0.0219, Accuracy: 15.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100: 100%|██████████| 3303/3303 [03:04<00:00, 17.91it/s, accuracy=15.91%, loss=0.0214]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 completed. Loss: 0.0214, Accuracy: 15.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.84it/s, accuracy=16.34%, loss=0.021]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 completed. Loss: 0.0210, Accuracy: 16.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.83it/s, accuracy=16.68%, loss=0.0207]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 completed. Loss: 0.0207, Accuracy: 16.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.82it/s, accuracy=16.96%, loss=0.0204]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 completed. Loss: 0.0204, Accuracy: 16.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100: 100%|██████████| 3303/3303 [03:04<00:00, 17.86it/s, accuracy=17.22%, loss=0.0202]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 completed. Loss: 0.0202, Accuracy: 17.22%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.78it/s, accuracy=17.41%, loss=0.02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 completed. Loss: 0.0200, Accuracy: 17.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/100: 100%|██████████| 3303/3303 [03:04<00:00, 17.90it/s, accuracy=17.58%, loss=0.0198]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 completed. Loss: 0.0198, Accuracy: 17.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.79it/s, accuracy=17.71%, loss=0.0196]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 completed. Loss: 0.0196, Accuracy: 17.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/100: 100%|██████████| 3303/3303 [03:04<00:00, 17.87it/s, accuracy=17.82%, loss=0.0195]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 completed. Loss: 0.0195, Accuracy: 17.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.81it/s, accuracy=17.94%, loss=0.0194]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 completed. Loss: 0.0194, Accuracy: 17.94%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.80it/s, accuracy=18.01%, loss=0.0193]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 completed. Loss: 0.0193, Accuracy: 18.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/100: 100%|██████████| 3303/3303 [03:04<00:00, 17.94it/s, accuracy=18.08%, loss=0.0192]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 completed. Loss: 0.0192, Accuracy: 18.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.79it/s, accuracy=18.14%, loss=0.0191]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 completed. Loss: 0.0191, Accuracy: 18.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/100: 100%|██████████| 3303/3303 [03:04<00:00, 17.85it/s, accuracy=18.19%, loss=0.019]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 completed. Loss: 0.0190, Accuracy: 18.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/100: 100%|██████████| 3303/3303 [03:04<00:00, 17.86it/s, accuracy=18.24%, loss=0.019]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 completed. Loss: 0.0190, Accuracy: 18.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.81it/s, accuracy=18.27%, loss=0.0189]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 completed. Loss: 0.0189, Accuracy: 18.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.84it/s, accuracy=18.29%, loss=0.0189]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 completed. Loss: 0.0189, Accuracy: 18.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/100: 100%|██████████| 3303/3303 [03:04<00:00, 17.88it/s, accuracy=18.32%, loss=0.0188]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 completed. Loss: 0.0188, Accuracy: 18.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.82it/s, accuracy=18.35%, loss=0.0188]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 completed. Loss: 0.0188, Accuracy: 18.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.84it/s, accuracy=18.38%, loss=0.0187]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 completed. Loss: 0.0187, Accuracy: 18.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/100: 100%|██████████| 3303/3303 [03:06<00:00, 17.71it/s, accuracy=18.39%, loss=0.0187]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 completed. Loss: 0.0187, Accuracy: 18.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.85it/s, accuracy=18.43%, loss=0.0187]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 completed. Loss: 0.0187, Accuracy: 18.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/100: 100%|██████████| 3303/3303 [03:04<00:00, 17.95it/s, accuracy=18.46%, loss=0.0186]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 completed. Loss: 0.0186, Accuracy: 18.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.80it/s, accuracy=18.46%, loss=0.0186]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 completed. Loss: 0.0186, Accuracy: 18.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.78it/s, accuracy=18.47%, loss=0.0186]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 completed. Loss: 0.0186, Accuracy: 18.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.81it/s, accuracy=18.49%, loss=0.0186]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 completed. Loss: 0.0186, Accuracy: 18.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.76it/s, accuracy=18.48%, loss=0.0185]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 completed. Loss: 0.0185, Accuracy: 18.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.84it/s, accuracy=18.52%, loss=0.0185]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 completed. Loss: 0.0185, Accuracy: 18.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/100: 100%|██████████| 3303/3303 [03:04<00:00, 17.88it/s, accuracy=18.49%, loss=0.0185]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 completed. Loss: 0.0185, Accuracy: 18.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/100: 100%|██████████| 3303/3303 [03:06<00:00, 17.74it/s, accuracy=18.52%, loss=0.0185]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 completed. Loss: 0.0185, Accuracy: 18.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/100: 100%|██████████| 3303/3303 [03:06<00:00, 17.74it/s, accuracy=18.54%, loss=0.0185]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 completed. Loss: 0.0185, Accuracy: 18.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.78it/s, accuracy=18.55%, loss=0.0185]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 completed. Loss: 0.0185, Accuracy: 18.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/100: 100%|██████████| 3303/3303 [03:04<00:00, 17.86it/s, accuracy=18.54%, loss=0.0184]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 completed. Loss: 0.0184, Accuracy: 18.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/100: 100%|██████████| 3303/3303 [03:04<00:00, 17.94it/s, accuracy=18.56%, loss=0.0184]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 completed. Loss: 0.0184, Accuracy: 18.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.80it/s, accuracy=18.56%, loss=0.0184]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 completed. Loss: 0.0184, Accuracy: 18.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/100: 100%|██████████| 3303/3303 [03:06<00:00, 17.76it/s, accuracy=18.60%, loss=0.0184]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 completed. Loss: 0.0184, Accuracy: 18.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.76it/s, accuracy=18.57%, loss=0.0184]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 completed. Loss: 0.0184, Accuracy: 18.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/100: 100%|██████████| 3303/3303 [03:06<00:00, 17.74it/s, accuracy=18.57%, loss=0.0184]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 completed. Loss: 0.0184, Accuracy: 18.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/100: 100%|██████████| 3303/3303 [03:04<00:00, 17.87it/s, accuracy=18.60%, loss=0.0184]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 completed. Loss: 0.0184, Accuracy: 18.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.85it/s, accuracy=18.59%, loss=0.0184]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 completed. Loss: 0.0184, Accuracy: 18.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.82it/s, accuracy=18.59%, loss=0.0183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 completed. Loss: 0.0183, Accuracy: 18.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.84it/s, accuracy=18.61%, loss=0.0183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 completed. Loss: 0.0183, Accuracy: 18.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.80it/s, accuracy=18.62%, loss=0.0183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 completed. Loss: 0.0183, Accuracy: 18.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.78it/s, accuracy=18.62%, loss=0.0183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 completed. Loss: 0.0183, Accuracy: 18.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/100: 100%|██████████| 3303/3303 [03:03<00:00, 18.00it/s, accuracy=18.60%, loss=0.0183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 completed. Loss: 0.0183, Accuracy: 18.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.78it/s, accuracy=18.65%, loss=0.0183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 completed. Loss: 0.0183, Accuracy: 18.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.80it/s, accuracy=18.60%, loss=0.0183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 completed. Loss: 0.0183, Accuracy: 18.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 51/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.80it/s, accuracy=18.61%, loss=0.0183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51 completed. Loss: 0.0183, Accuracy: 18.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 52/100: 100%|██████████| 3303/3303 [03:06<00:00, 17.74it/s, accuracy=18.65%, loss=0.0183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52 completed. Loss: 0.0183, Accuracy: 18.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 53/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.79it/s, accuracy=18.63%, loss=0.0183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53 completed. Loss: 0.0183, Accuracy: 18.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 54/100: 100%|██████████| 3303/3303 [03:06<00:00, 17.72it/s, accuracy=18.63%, loss=0.0183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54 completed. Loss: 0.0183, Accuracy: 18.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 55/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.81it/s, accuracy=18.67%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55 completed. Loss: 0.0182, Accuracy: 18.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 56/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.81it/s, accuracy=18.63%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56 completed. Loss: 0.0182, Accuracy: 18.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 57/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.82it/s, accuracy=18.66%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57 completed. Loss: 0.0182, Accuracy: 18.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 58/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.80it/s, accuracy=18.64%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58 completed. Loss: 0.0182, Accuracy: 18.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 59/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.85it/s, accuracy=18.65%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59 completed. Loss: 0.0182, Accuracy: 18.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 60/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.80it/s, accuracy=18.62%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60 completed. Loss: 0.0182, Accuracy: 18.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 61/100: 100%|██████████| 3303/3303 [03:05<00:00, 17.82it/s, accuracy=18.66%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61 completed. Loss: 0.0182, Accuracy: 18.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 62/100: 100%|██████████| 3303/3303 [03:06<00:00, 17.75it/s, accuracy=18.67%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62 completed. Loss: 0.0182, Accuracy: 18.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 63/100: 100%|██████████| 3303/3303 [03:07<00:00, 17.58it/s, accuracy=18.69%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63 completed. Loss: 0.0182, Accuracy: 18.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 64/100: 100%|██████████| 3303/3303 [03:07<00:00, 17.62it/s, accuracy=18.66%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64 completed. Loss: 0.0182, Accuracy: 18.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 65/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.48it/s, accuracy=18.66%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65 completed. Loss: 0.0182, Accuracy: 18.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 66/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.51it/s, accuracy=18.66%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66 completed. Loss: 0.0182, Accuracy: 18.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 67/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.40it/s, accuracy=18.64%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67 completed. Loss: 0.0182, Accuracy: 18.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 68/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.49it/s, accuracy=18.67%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68 completed. Loss: 0.0182, Accuracy: 18.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 69/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.53it/s, accuracy=18.65%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69 completed. Loss: 0.0182, Accuracy: 18.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 70/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.47it/s, accuracy=18.67%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70 completed. Loss: 0.0182, Accuracy: 18.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 71/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.48it/s, accuracy=18.68%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71 completed. Loss: 0.0182, Accuracy: 18.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 72/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.47it/s, accuracy=18.66%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72 completed. Loss: 0.0182, Accuracy: 18.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 73/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.46it/s, accuracy=18.67%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73 completed. Loss: 0.0182, Accuracy: 18.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 74/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.42it/s, accuracy=18.70%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74 completed. Loss: 0.0182, Accuracy: 18.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 75/100: 100%|██████████| 3303/3303 [03:07<00:00, 17.58it/s, accuracy=18.68%, loss=0.0182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75 completed. Loss: 0.0182, Accuracy: 18.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 76/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.42it/s, accuracy=18.70%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76 completed. Loss: 0.0181, Accuracy: 18.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 77/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.40it/s, accuracy=18.68%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77 completed. Loss: 0.0181, Accuracy: 18.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 78/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.47it/s, accuracy=18.67%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78 completed. Loss: 0.0181, Accuracy: 18.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 79/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.46it/s, accuracy=18.64%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79 completed. Loss: 0.0181, Accuracy: 18.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 80/100: 100%|██████████| 3303/3303 [03:07<00:00, 17.62it/s, accuracy=18.69%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80 completed. Loss: 0.0181, Accuracy: 18.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 81/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.41it/s, accuracy=18.67%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81 completed. Loss: 0.0181, Accuracy: 18.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 82/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.51it/s, accuracy=18.70%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82 completed. Loss: 0.0181, Accuracy: 18.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 83/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.46it/s, accuracy=18.66%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83 completed. Loss: 0.0181, Accuracy: 18.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 84/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.53it/s, accuracy=18.70%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84 completed. Loss: 0.0181, Accuracy: 18.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 85/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.55it/s, accuracy=18.66%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85 completed. Loss: 0.0181, Accuracy: 18.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 86/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.50it/s, accuracy=18.67%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86 completed. Loss: 0.0181, Accuracy: 18.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 87/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.44it/s, accuracy=18.68%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87 completed. Loss: 0.0181, Accuracy: 18.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 88/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.52it/s, accuracy=18.71%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88 completed. Loss: 0.0181, Accuracy: 18.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 89/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.45it/s, accuracy=18.72%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89 completed. Loss: 0.0181, Accuracy: 18.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 90/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.51it/s, accuracy=18.72%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90 completed. Loss: 0.0181, Accuracy: 18.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 91/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.56it/s, accuracy=18.70%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91 completed. Loss: 0.0181, Accuracy: 18.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 92/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.48it/s, accuracy=18.68%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92 completed. Loss: 0.0181, Accuracy: 18.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 93/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.47it/s, accuracy=18.72%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93 completed. Loss: 0.0181, Accuracy: 18.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 94/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.44it/s, accuracy=18.69%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94 completed. Loss: 0.0181, Accuracy: 18.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 95/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.47it/s, accuracy=18.69%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95 completed. Loss: 0.0181, Accuracy: 18.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 96/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.53it/s, accuracy=18.69%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96 completed. Loss: 0.0181, Accuracy: 18.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 97/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.44it/s, accuracy=18.68%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97 completed. Loss: 0.0181, Accuracy: 18.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 98/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.41it/s, accuracy=18.71%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98 completed. Loss: 0.0181, Accuracy: 18.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 99/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.49it/s, accuracy=18.69%, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99 completed. Loss: 0.0181, Accuracy: 18.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 100/100: 100%|██████████| 3303/3303 [03:06<00:00, 17.75it/s, accuracy=18.69%, loss=0.0181]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100 completed. Loss: 0.0181, Accuracy: 18.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "def build_char_vocab(corpus):\n",
        "    char_set = set()\n",
        "    for predictor, target in corpus:\n",
        "        char_set.update(predictor)\n",
        "        char_set.update(target)\n",
        "    char_vocab = {'<pad>': 0, '<unk>': 1}\n",
        "    char_vocab.update({char: idx + 2 for idx, char in enumerate(sorted(char_set))})\n",
        "    return char_vocab\n",
        "\n",
        "def build_word_vocab(corpus):\n",
        "    word_set = set()\n",
        "    for predictor, target in corpus:\n",
        "        word_set.update([predictor, target])\n",
        "    print(\"Total unique words not presets:\", len(word_set))\n",
        "    word_vocab = {'<pad>': 0}\n",
        "    word_vocab.update({word: idx + 1 for idx, word in enumerate(sorted(word_set))})\n",
        "    print(\"Total unique words including <pad> and <unk>:\", len(word_set) + 1)\n",
        "    return word_vocab\n",
        "\n",
        "corpus = [\n",
        "    \"Hello world\",\n",
        "    \"This is an example sentence\",\n",
        "    \"To be or not to be, that is the question\",\n",
        "    \"I think, therefore I am\",\n",
        "    \"A journey of a thousand miles begins with a single step\",\n",
        "    \"All that glitters is not gold\",\n",
        "    \"Ask not what your country can do for you, ask what you can do for your country\",\n",
        "    \"I have a dream\",\n",
        "    \"Elementary, my dear Watson\",\n",
        "    \"Houston, we have a problem\",\n",
        "    \"Just keep swimming\",\n",
        "    \"May the Force be with you\",\n",
        "    \"Once upon a time in a land far, far away\",\n",
        "    \"Winter is coming\",\n",
        "    \"Keep calm and carry on\",\n",
        "    \"Why so serious?\",\n",
        "    \"There's no place like home\",\n",
        "    # \"The cake is a lie\",\n",
        "    # \"To infinity and beyond\",\n",
        "    # \"Elementary, my dear Watson\",\n",
        "    # \"It's a trap!\",\n",
        "    # \"Life is like a box of chocolates\",\n",
        "    # \"The pen is mightier than the sword\",\n",
        "    # \"Knowledge is power\",\n",
        "    # \"With great power comes great responsibility\",\n",
        "    # \"The only thing we have to fear is fear itself\",\n",
        "    # \"I have a dream\",\n",
        "    # \"That's one small step for man, one giant leap for mankind\",\n",
        "    # \"In the beginning, the universe was created\",\n",
        "    # \"I'm just a simple man trying to make my way in the universe\",\n",
        "    # \"Do or do not, there is no try\",\n",
        "    # \"To boldly go where no one has gone before\",\n",
        "    # \"A long time ago in a galaxy far, far away\",\n",
        "    # \"Et tu, Brute?\",\n",
        "    # \"You can't handle the truth!\",\n",
        "    # \"I'm the king of the world!\",\n",
        "    # \"They may take our lives, but they'll never take our freedom!\",\n",
        "    # \"Frankly, my dear, I don't give a damn\",\n",
        "    # \"You talking to me?\",\n",
        "    # \"Here's looking at you, kid\",\n",
        "    # \"I love the smell of napalm in the morning\",\n",
        "    # \"Say hello to my little friend\",\n",
        "    # \"Houston, we have a problem\",\n",
        "    # \"I'm gonna make him an offer he can't refuse\",\n",
        "    # \"Keep your friends close, but your enemies closer\",\n",
        "    # \"I feel the need—the need for speed\",\n",
        "    # \"Carpe diem. Seize the day, boys\",\n",
        "    # \"Elementary, my dear Watson\",\n",
        "    # \"Life moves pretty fast. If you don't stop and look around once in a while, you could miss it\",\n",
        "    # \"Nobody puts Baby in a corner\"\n",
        "]\n",
        "\n",
        "train_corpus = preprocess_data(train_data)\n",
        "\n",
        "char_vocab = build_char_vocab(train_corpus)\n",
        "word_vocab = build_word_vocab(train_corpus)\n",
        "\n",
        "char_vocab_size = len(char_vocab)\n",
        "char_embed_dim = 50\n",
        "word_vocab_size = len(word_vocab)\n",
        "print(\"word vocab size:\", word_vocab_size)\n",
        "conv_out_size = 256\n",
        "hidden_dim = 512\n",
        "'''\n",
        "from figure 1: Note that in the above\n",
        "example we have twelve filters—three filters of width two\n",
        "(blue), four filters of width three (yellow), and five filters\n",
        "of width four (red). Just added one more possibility (5)\n",
        "'''\n",
        "kernel_sizes = [2, 3, 4, 5]\n",
        "features = [64, 64, 64, 64]\n",
        "num_highway_layers = 2\n",
        "num_rnn_layers = 2\n",
        "dropout = 0.1\n",
        "\n",
        "model = CharacterToWordModel(char_vocab_size, char_embed_dim, word_vocab_size,\n",
        "                             conv_out_size, hidden_dim, kernel_sizes, features,\n",
        "                             num_highway_layers, num_rnn_layers, dropout)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.dtype)\n",
        "\n",
        "model.to(device)\n",
        "max_sequence_length = 50\n",
        "train_predictors, train_targets = data_to_tensors(train_corpus, char_vocab, word_vocab, max_sequence_length)\n",
        "\n",
        "batch_size = 256\n",
        "train_dataset = TensorDataset(train_predictors, train_targets)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "num_epochs = 100\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
        "\n",
        "    for inputs, targets in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        hidden_state = None\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        predictions, _ = model(inputs, hidden_state)\n",
        "\n",
        "        if targets.max() >= word_vocab_size:\n",
        "            print(\"Invalid target index found:\", targets.max())\n",
        "            print(\"Inputs:\", inputs)\n",
        "            print(\"Inputs Shape:\", inputs.shape)\n",
        "            print(\"Targets:\", targets)\n",
        "            print(\"Targets Shape:\", targets)\n",
        "            break\n",
        "\n",
        "        loss = criterion(predictions.view(-1, word_vocab_size), targets.view(-1)).to(device)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(predictions.data, -1)\n",
        "        total_correct += (predicted.view(-1) == targets.view(-1)).sum().item()\n",
        "        total_samples += targets.numel()\n",
        "\n",
        "        avg_loss = total_loss / total_samples\n",
        "        accuracy = total_correct / total_samples * 100\n",
        "        progress_bar.set_postfix(loss=avg_loss, accuracy=f'{accuracy:.2f}%')\n",
        "\n",
        "    print(f\"Epoch {epoch+1} completed. Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_yhKNw4_Pxr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCIKnPpv_Pxr"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_predictors, test_targets = data_to_tensors(test_corpus, char_vocab, word_vocab, max_sequence_length, sequence_count)\n",
        "\n",
        "batch_size = 20\n",
        "train_dataset = TensorDataset(train_predictors, train_targets)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# # validation and test datasets\n",
        "# valid_dataset = TensorDataset(valid_predictors, valid_targets)\n",
        "# valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_dataset = TensorDataset(test_predictors, test_targets)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_corpus = preprocess_data(train_data)\n",
        "\n",
        "test_char_vocab = build_char_vocab(test_corpus)\n",
        "test_word_vocab = build_word_vocab(test_corpus)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.dtype)\n",
        "\n",
        "model.to(device)\n",
        "max_sequence_length = 50\n",
        "test_predictors, test_targets = data_to_tensors(test_corpus, test_char_vocab, test_word_vocab, max_sequence_length)\n",
        "\n",
        "batch_size = 256\n",
        "test_dataset = TensorDataset(test_predictors, test_targets)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# import torch.optim as optim\n",
        "\n",
        "# from tqdm import tqdm\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "def calculate_perplexity(model, data_loader, criterion):\n",
        "    model.eval()  # eval mode\n",
        "    total_loss = 0\n",
        "    total_words = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs, _ = model(inputs, None)\n",
        "            loss = criterion(outputs.view(-1, word_vocab_size), targets.view(-1))\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            total_words += inputs.size(0)\n",
        "\n",
        "    average_loss = total_loss / total_words\n",
        "    perplexity = math.exp(average_loss)\n",
        "\n",
        "    return perplexity\n",
        "\n",
        "perplexity = calculate_perplexity(model, test_loader, criterion)\n",
        "print(\"Perplexity:\", perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DEiKqgrD9Xb",
        "outputId": "58aea618-915a-446e-acff-3ac83e760b79"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique words not presets: 9998\n",
            "Total unique words including <pad> and <unk>: 9999\n",
            "char_embedding.weight torch.float32\n",
            "conv_net.conv_blocks.0.conv_layer.weight torch.float32\n",
            "conv_net.conv_blocks.0.conv_layer.bias torch.float32\n",
            "conv_net.conv_blocks.1.conv_layer.weight torch.float32\n",
            "conv_net.conv_blocks.1.conv_layer.bias torch.float32\n",
            "conv_net.conv_blocks.2.conv_layer.weight torch.float32\n",
            "conv_net.conv_blocks.2.conv_layer.bias torch.float32\n",
            "conv_net.conv_blocks.3.conv_layer.weight torch.float32\n",
            "conv_net.conv_blocks.3.conv_layer.bias torch.float32\n",
            "highway_net.highway_block_0.trans_bias torch.float32\n",
            "highway_net.highway_block_0.project.weight torch.float32\n",
            "highway_net.highway_block_0.project.bias torch.float32\n",
            "highway_net.highway_block_0.transform.weight torch.float32\n",
            "highway_net.highway_block_0.transform.bias torch.float32\n",
            "highway_net.highway_block_1.trans_bias torch.float32\n",
            "highway_net.highway_block_1.project.weight torch.float32\n",
            "highway_net.highway_block_1.project.bias torch.float32\n",
            "highway_net.highway_block_1.transform.weight torch.float32\n",
            "highway_net.highway_block_1.transform.bias torch.float32\n",
            "rnn_net.rnn_layers.weight_ih_l0 torch.float32\n",
            "rnn_net.rnn_layers.weight_hh_l0 torch.float32\n",
            "rnn_net.rnn_layers.bias_ih_l0 torch.float32\n",
            "rnn_net.rnn_layers.bias_hh_l0 torch.float32\n",
            "rnn_net.rnn_layers.weight_ih_l1 torch.float32\n",
            "rnn_net.rnn_layers.weight_hh_l1 torch.float32\n",
            "rnn_net.rnn_layers.bias_ih_l1 torch.float32\n",
            "rnn_net.rnn_layers.bias_hh_l1 torch.float32\n",
            "output_layer.weight torch.float32\n",
            "output_layer.bias torch.float32\n",
            "Perplexity: 88.7196591145479\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}