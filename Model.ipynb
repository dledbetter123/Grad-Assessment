{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source ~/venv-ptmetal/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.backends.mps.is_available():\n",
    "   device = \"mps\"\n",
    "   x = torch.ones(1).to(\"mps\")\n",
    "   print (x)\n",
    "else:\n",
    "   print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Time:  10.581156015396118\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.mps.synchronize()\n",
    "a = torch.ones(32000,32000).to(device)\n",
    "for _ in range(500):\n",
    "   a +=a\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print( \"GPU Time: \", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non GPU Time:  21.180355072021484\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.mps.synchronize()\n",
    "\n",
    "a = torch.ones(32000,32000)\n",
    "for _ in range(500):\n",
    "   a +=a\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print( \"Non GPU Time: \", elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, '<unk>': 1, ' ': 2, 'H': 3, 'T': 4, 'a': 5, 'c': 6, 'd': 7, 'e': 8, 'h': 9, 'i': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'r': 16, 's': 17, 't': 18, 'w': 19, 'x': 20}\n",
      "{'<pad>': 0, '<unk>': 1, 'Hello': 2, 'This': 3, 'sentence': 4, 'example': 5, 'is': 6, 'an': 7, 'world': 8}\n"
     ]
    }
   ],
   "source": [
    "# new way to tokenize\n",
    "def build_char_vocab(corpus):\n",
    "    char_set = set()\n",
    "    for sentence in corpus:\n",
    "        char_set.update(sentence)\n",
    "    # <pad> and <unk>\n",
    "    char_vocab = {'<pad>': 0, '<unk>': 1}\n",
    "    char_vocab.update({char: idx + 2 for idx, char in enumerate(sorted(char_set))})\n",
    "    return char_vocab\n",
    "\n",
    "corpus = [\"Hello world\", \"This is an example sentence\"]\n",
    "char_vocab = build_char_vocab(corpus)\n",
    "print(char_vocab)\n",
    "\n",
    "def build_word_vocab(corpus):\n",
    "    word_set = set()\n",
    "    for sentence in corpus:\n",
    "        word_set.update(sentence.split())\n",
    "    # Adding <pad> and <unk>\n",
    "    word_vocab = {'<pad>': 0, '<unk>': 1}  # gonna assume it doesn't need to be sorted, read that we don't need it rn.\n",
    "    word_vocab.update({word: idx + 2 for idx, word in enumerate(word_set)})\n",
    "    return word_vocab\n",
    "\n",
    "corpus = [\"Hello world\", \"This is an example sentence\"]\n",
    "word_vocab = build_word_vocab(corpus)\n",
    "print(word_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9,  8, 11, 11, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [19, 14, 16, 11,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [18,  9, 10, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [10, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 5, 13,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 8, 20,  5, 12, 15, 11,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [17,  8, 13, 18,  8, 13,  6,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "# def one_hot_encode(index, vocab_size):\n",
    "#     one_hot = torch.zeros(vocab_size)\n",
    "#     one_hot[index] = 1\n",
    "#     return one_hot\n",
    "\n",
    "# def preprocess_corpus(corpus, char_vocab, max_length):\n",
    "#     vocab_size = len(char_vocab)\n",
    "#     processed_corpus = []\n",
    "#     for sentence in corpus:\n",
    "#         sentence_indices = [char_vocab.get(char, char_vocab['<unk>']) for char in sentence.lower()]\n",
    "#         padded_indices = sentence_indices + [char_vocab['<pad>']] * (max_length - len(sentence_indices))\n",
    "#         # one_hot_sentence = [one_hot_encode(index, vocab_size) for index in padded_indices[:max_length]]\n",
    "#         processed_corpus.append(torch.stack(one_hot_sentence))\n",
    "#     return torch.stack(processed_corpus)\n",
    "\n",
    "'''\n",
    " Do not need one hot encoding. \n",
    " will shrink char_embed dims to align with Character-level \n",
    " Convolutional Neural Network section in paper later on. i.e. d < |C|\n",
    "'''\n",
    "\n",
    "def preprocess_corpus(corpus, char_vocab, max_length=30):\n",
    "    # words should be lowercase, then tokenized, map characters to indices, and pad to max_length\n",
    "    processed_corpus = []\n",
    "    for sentence in corpus:\n",
    "        words = sentence.split()\n",
    "        for word in words:\n",
    "            word_indices = [char_vocab.get(char, char_vocab['<unk>']) for char in word.lower()]\n",
    "            # pad to max_length\n",
    "            padded_indices = word_indices + [char_vocab['<pad>']] * (max_length - len(word_indices))\n",
    "            processed_corpus.append(padded_indices[:max_length])\n",
    "    return processed_corpus\n",
    "\n",
    "corpus = [\"Hello world\", \"This is an example sentence\"]\n",
    "\n",
    "processed_corpus = preprocess_corpus(corpus, char_vocab)\n",
    "\n",
    "input_tensor = torch.tensor(processed_corpus)\n",
    "print(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HighwayBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.project = nn.Linear(input_dim, output_dim)\n",
    "        self.transform = nn.Linear(input_dim, output_dim)\n",
    "        self.trans_bias = nn.Parameter(torch.tensor(-2.0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        proj_output = torch.relu(self.project(x))\n",
    "        trans_output = torch.sigmoid(self.transform(x) + self.trans_bias)\n",
    "        return trans_output * proj_output + (1 - trans_output) * x\n",
    "\n",
    "class HighwayNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.layers = []\n",
    "        for i in range(num_layers):\n",
    "            layer_size = input_size if i == 0 else output_size\n",
    "            self.layers.append(HighwayBlock(layer_size, output_size))\n",
    "            self.add_module(f'highway_block_{i}', self.layers[-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class ConvolutionBlock(nn.Module):\n",
    "    def __init__(self, channels, kernel, features):\n",
    "        super().__init__()\n",
    "        self.conv_layer = nn.Conv2d(channels, features, kernel)\n",
    "\n",
    "    def forward(self, x, size_reduce):\n",
    "        conv_output = torch.tanh(self.conv_layer(x))\n",
    "        pooled_output = F.max_pool2d(conv_output, kernel_size=[1, size_reduce])\n",
    "        return pooled_output.squeeze(3).squeeze(2)\n",
    "\n",
    "class ConvolutionNetwork(nn.Module):\n",
    "    def __init__(self, channel_size, kernel_sizes, feature_sizes):\n",
    "        super().__init__()\n",
    "        self.conv_blocks = nn.ModuleList()\n",
    "\n",
    "        # applies the filters of differenent widths over input\n",
    "        for i, (k_size, f_size) in enumerate(zip(kernel_sizes, feature_sizes)):\n",
    "            self.conv_blocks.append(ConvolutionBlock(channel_size, (1, k_size), f_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # squeezes output to accomodate for batches\n",
    "        x = x.unsqueeze(2).transpose(1, 3)\n",
    "        conv_outputs = [block(x, x.size(3) - k_size + 1) for block, k_size in zip(self.conv_blocks, kernel_sizes)]\n",
    "        return torch.cat(conv_outputs, 1)\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.rnn_layers = nn.LSTM(input_size, hidden_size, num_layers=num_layers, dropout=dropout_rate)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    # use this instead of hidden state init outside\n",
    "    def init_hidden_state(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        output, hidden = self.rnn_layers(x, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "class CharacterToWordModel(nn.Module):\n",
    "    def __init__(self, char_vocab_size, char_embed_dim, word_vocab_size, \n",
    "                 conv_out_size, hidden_dim, kernel_sizes, features, num_highway_layers, \n",
    "                 num_rnn_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.char_vocab_size = char_vocab_size\n",
    "        self.char_embed_dim = char_embed_dim\n",
    "        self.word_vocab_size = word_vocab_size\n",
    "        self.conv_out_size = conv_out_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_rate = dropout\n",
    "\n",
    "        self.char_embedding = nn.Embedding(char_vocab_size, char_embed_dim, padding_idx=0)\n",
    "        # print(\"charvocab\", char_vocab_size, \"char_embed_dim\", char_embed_dim)\n",
    "        self.conv_net = ConvolutionNetwork(char_embed_dim, kernel_sizes, features)\n",
    "        self.highway_net = HighwayNetwork(conv_out_size, conv_out_size, num_highway_layers)\n",
    "        self.rnn_net = RNN(conv_out_size, hidden_dim, num_rnn_layers, dropout)\n",
    "        self.output_layer = nn.Linear(hidden_dim, word_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.initw()\n",
    "\n",
    "    def initw(self):\n",
    "        rng = 0.1\n",
    "        self.char_embedding.weight.data.uniform_(-rng, rng)\n",
    "        self.output_layer.bias.data.fill_(0)\n",
    "        self.output_layer.weight.data.uniform_(-rng, rng)\n",
    "\n",
    "    def forward(self, input_chars, hidden_state):\n",
    "        # print(\"input shape\", input_chars.shape)\n",
    "        emb = self.char_embedding(input_chars)\n",
    "        # print(\"embedding shape\", emb.shape)\n",
    "        conv_output = self.conv_net(emb)\n",
    "        highway_output = self.highway_net(conv_output)\n",
    "        rnn_output, hidden_state = self.rnn_net(highway_output, hidden_state)\n",
    "        rnn_output = self.dropout(rnn_output)\n",
    "        final_output = self.output_layer(rnn_output.view(-1, self.hidden_dim))\n",
    "        top_word_indices = torch.argmax(final_output, dim=-1)\n",
    "        return final_output, hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "[('Hello', 'world'), ('This', 'is'), ('is', 'an'), ('an', 'example'), ('example', 'sentence'), ('To', 'be'), ('be', 'or'), ('or', 'not'), ('not', 'to'), ('to', 'be,'), ('be,', 'that'), ('that', 'is'), ('is', 'the'), ('the', 'question'), ('I', 'think,'), ('think,', 'therefore'), ('therefore', 'I'), ('I', 'am')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_dataset(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.readlines()\n",
    "    return data\n",
    "\n",
    "train_data = load_dataset('train.txt')\n",
    "valid_data = load_dataset('valid.txt')\n",
    "test_data = load_dataset('test.txt')\n",
    "\n",
    "\n",
    "def preprocess_data(data):\n",
    "    corpus = []\n",
    "\n",
    "    for sentence in data:\n",
    "\n",
    "        words = sentence.strip().split()\n",
    "        for i in range(len(words) - 1):\n",
    "\n",
    "            predictor, target = words[i], words[i + 1]\n",
    "\n",
    "            corpus.append((predictor, target))\n",
    "    return corpus\n",
    "testing = [\n",
    "    \"Hello world\",\n",
    "    \"This is an example sentence\",\n",
    "    \"To be or not to be, that is the question\",\n",
    "    \"I think, therefore I am\",]\n",
    "\n",
    "test = preprocess_data(testing)\n",
    "print(len(test))\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# def data_to_tensors(corpus, char_vocab, word_vocab):\n",
    "#     predictors = []\n",
    "#     targets = []\n",
    "#     for predictor, target in corpus:\n",
    "#         predictor_indices = [char_vocab.get(char, char_vocab['<unk>']) for char in predictor]\n",
    "#         # print(predictors)\n",
    "#         target_index = word_vocab.get(target, word_vocab['<unk>'])\n",
    "#         predictors.append(predictor_indices)\n",
    "#         targets.append(target_index)\n",
    "#     print(len(predictors))\n",
    "#     print(len(targets))\n",
    "#     return torch.tensor(predictors), torch.tensor(targets)\n",
    "\n",
    "# train_predictors, train_targets = data_to_tensors(train_corpus, char_vocab, word_vocab)\n",
    "# valid_predictors, valid_targets = data_to_tensors(valid_corpus, char_vocab, word_vocab)\n",
    "# test_predictors, test_targets = data_to_tensors(test_corpus, char_vocab, word_vocab)\n",
    "\n",
    "def data_to_tensors(corpus, char_vocab, word_vocab, max_sequence_length):\n",
    "    predictors = []\n",
    "    targets = []\n",
    "\n",
    "    for predictor, target in corpus:\n",
    "        predictor_indices = [char_vocab.get(char, char_vocab['<unk>']) for char in predictor]\n",
    "        target_index = word_vocab.get(target, word_vocab['<unk>'])\n",
    "        \n",
    "        # Pad the predictor sequence\n",
    "        if len(predictor_indices) < max_sequence_length:\n",
    "            predictor_indices += [char_vocab['<pad>']] * (max_sequence_length - len(predictor_indices))\n",
    "        else:\n",
    "            predictor_indices = predictor_indices[:max_sequence_length]\n",
    "\n",
    "        predictors.append(predictor_indices)\n",
    "        targets.append(target_index)\n",
    "\n",
    "    return torch.tensor(predictors), torch.tensor(targets)\n",
    "\n",
    "# train_predictors, train_targets = data_to_tensors(train_corpus, char_vocab, word_vocab, max_sequence_length)\n",
    "# valid_predictors, valid_targets = data_to_tensors(valid_corpus, char_vocab, word_vocab, max_sequence_length)\n",
    "# test_predictors, test_targets = data_to_tensors(test_corpus, char_vocab, word_vocab, max_sequence_length)\n",
    "\n",
    "# batch_size = 20\n",
    "# train_dataset = TensorDataset(train_predictors, train_targets)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/davidledbetter/miniconda/envs/tf/lib/python3.9/site-packages (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word vocab size: 9999\n",
      "torch.Size([845453])\n"
     ]
    }
   ],
   "source": [
    "def build_char_vocab(corpus):\n",
    "    char_set = set()\n",
    "    for predictor, target in corpus:\n",
    "        char_set.update(predictor)\n",
    "        char_set.update(target)\n",
    "\n",
    "    char_vocab = {'<pad>': 0, '<unk>': 1}\n",
    "    char_vocab.update({char: idx + 2 for idx, char in enumerate(sorted(char_set))})\n",
    "    return char_vocab\n",
    "\n",
    "def build_word_vocab(corpus):\n",
    "    word_set = set()\n",
    "    for predictor, target in corpus:\n",
    "        word_set.update([predictor, target])\n",
    "\n",
    "    # do not need to add , '<unk>': 1 since it is in dataset already.\n",
    "    word_vocab = {'<pad>': 0}\n",
    "\n",
    "    # update at idx + 1 instead of idx + 2 because we've removed <unk>\n",
    "    word_vocab.update({word: idx + 1 for idx, word in enumerate(sorted(word_set))})\n",
    "    return word_vocab\n",
    "\n",
    "corpus = [\n",
    "    \"Hello world\",\n",
    "    \"This is an example sentence\",\n",
    "    \"To be or not to be, that is the question\",\n",
    "    \"I think, therefore I am\",\n",
    "    \"A journey of a thousand miles begins with a single step\",\n",
    "    \"All that glitters is not gold\",\n",
    "    \"Ask not what your country can do for you, ask what you can do for your country\",\n",
    "    \"I have a dream\",\n",
    "    \"Elementary, my dear Watson\",\n",
    "    \"Houston, we have a problem\",\n",
    "    \"Just keep swimming\",\n",
    "    \"May the Force be with you\",\n",
    "    \"Once upon a time in a land far, far away\",\n",
    "    \"Winter is coming\",\n",
    "    \"Keep calm and carry on\",\n",
    "    \"Why so serious?\",\n",
    "    \"There's no place like home\",\n",
    "    # \"The cake is a lie\",\n",
    "    # \"To infinity and beyond\",\n",
    "    # \"Elementary, my dear Watson\",\n",
    "    # \"It's a trap!\",\n",
    "    # \"Life is like a box of chocolates\",\n",
    "    # \"The pen is mightier than the sword\",\n",
    "    # \"Knowledge is power\",\n",
    "    # \"With great power comes great responsibility\",\n",
    "    # \"The only thing we have to fear is fear itself\",\n",
    "    # \"I have a dream\",\n",
    "    # \"That's one small step for man, one giant leap for mankind\",\n",
    "    # \"In the beginning, the universe was created\",\n",
    "    # \"I'm just a simple man trying to make my way in the universe\",\n",
    "    # \"Do or do not, there is no try\",\n",
    "    # \"To boldly go where no one has gone before\",\n",
    "    # \"A long time ago in a galaxy far, far away\",\n",
    "    # \"Et tu, Brute?\",\n",
    "    # \"You can't handle the truth!\",\n",
    "    # \"I'm the king of the world!\",\n",
    "    # \"They may take our lives, but they'll never take our freedom!\",\n",
    "    # \"Frankly, my dear, I don't give a damn\",\n",
    "    # \"You talking to me?\",\n",
    "    # \"Here's looking at you, kid\",\n",
    "    # \"I love the smell of napalm in the morning\",\n",
    "    # \"Say hello to my little friend\",\n",
    "    # \"Houston, we have a problem\",\n",
    "    # \"I'm gonna make him an offer he can't refuse\",\n",
    "    # \"Keep your friends close, but your enemies closer\",\n",
    "    # \"I feel the need—the need for speed\",\n",
    "    # \"Carpe diem. Seize the day, boys\",\n",
    "    # \"Elementary, my dear Watson\",\n",
    "    # \"Life moves pretty fast. If you don't stop and look around once in a while, you could miss it\",\n",
    "    # \"Nobody puts Baby in a corner\"\n",
    "]\n",
    "\n",
    "train_corpus = preprocess_data(train_data)\n",
    "\n",
    "char_vocab = build_char_vocab(train_corpus)\n",
    "word_vocab = build_word_vocab(train_corpus)\n",
    "\n",
    "char_vocab_size = len(char_vocab)\n",
    "char_embed_dim = 50\n",
    "word_vocab_size = len(word_vocab)\n",
    "print(\"word vocab size:\", word_vocab_size)\n",
    "conv_out_size = 256\n",
    "hidden_dim = 512\n",
    "'''\n",
    "from figure 1: Note that in the above\n",
    "example we have twelve filters—three filters of width two\n",
    "(blue), four filters of width three (yellow), and five filters\n",
    "of width four (red). Just added one more possibility (5)\n",
    "'''\n",
    "kernel_sizes = [2, 3, 4, 5]\n",
    "features = [64, 64, 64, 64]  # same length as kernel_sizes\n",
    "num_highway_layers = 2\n",
    "num_rnn_layers = 2\n",
    "dropout = 0.1\n",
    "\n",
    "model = CharacterToWordModel(char_vocab_size, char_embed_dim, word_vocab_size, \n",
    "                             conv_out_size, hidden_dim, kernel_sizes, features, \n",
    "                             num_highway_layers, num_rnn_layers, dropout)\n",
    "model.to(device)\n",
    "\n",
    "max_sequence_length = 50\n",
    "train_predictors, train_targets = data_to_tensors(train_corpus, char_vocab, word_vocab, max_sequence_length)\n",
    "print(train_targets.size())\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "train_dataset = TensorDataset(train_predictors, train_targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 3303/3303 [03:06<00:00, 17.75it/s, accuracy=13.11%, loss=0.0234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Loss: 0.0234, Accuracy: 13.11%\n",
      "Model saved to model_saves/model_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 3303/3303 [03:06<00:00, 17.70it/s, accuracy=15.53%, loss=0.0218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed. Loss: 0.0218, Accuracy: 15.53%\n",
      "Model saved to model_saves/model_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.52it/s, accuracy=16.42%, loss=0.0211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed. Loss: 0.0211, Accuracy: 16.42%\n",
      "Model saved to model_saves/model_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 3303/3303 [03:10<00:00, 17.32it/s, accuracy=16.97%, loss=0.0206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed. Loss: 0.0206, Accuracy: 16.97%\n",
      "Model saved to model_saves/model_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 3303/3303 [03:10<00:00, 17.33it/s, accuracy=17.23%, loss=0.0202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed. Loss: 0.0202, Accuracy: 17.23%\n",
      "Model saved to model_saves/model_epoch_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 3303/3303 [03:10<00:00, 17.38it/s, accuracy=17.43%, loss=0.0199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed. Loss: 0.0199, Accuracy: 17.43%\n",
      "Model saved to model_saves/model_epoch_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 3303/3303 [03:10<00:00, 17.33it/s, accuracy=17.54%, loss=0.0197]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed. Loss: 0.0197, Accuracy: 17.54%\n",
      "Model saved to model_saves/model_epoch_7.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 3303/3303 [03:10<00:00, 17.38it/s, accuracy=17.61%, loss=0.0196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed. Loss: 0.0196, Accuracy: 17.61%\n",
      "Model saved to model_saves/model_epoch_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 3303/3303 [03:10<00:00, 17.32it/s, accuracy=17.67%, loss=0.0195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed. Loss: 0.0195, Accuracy: 17.67%\n",
      "Model saved to model_saves/model_epoch_9.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.52it/s, accuracy=17.73%, loss=0.0194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed. Loss: 0.0194, Accuracy: 17.73%\n",
      "Model saved to model_saves/model_epoch_10.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 3303/3303 [03:07<00:00, 17.60it/s, accuracy=17.76%, loss=0.0193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 completed. Loss: 0.0193, Accuracy: 17.76%\n",
      "Model saved to model_saves/model_epoch_11.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.40it/s, accuracy=17.75%, loss=0.0193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 completed. Loss: 0.0193, Accuracy: 17.75%\n",
      "Model saved to model_saves/model_epoch_12.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 3303/3303 [03:10<00:00, 17.36it/s, accuracy=17.81%, loss=0.0192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 completed. Loss: 0.0192, Accuracy: 17.81%\n",
      "Model saved to model_saves/model_epoch_13.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.40it/s, accuracy=17.83%, loss=0.0192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 completed. Loss: 0.0192, Accuracy: 17.83%\n",
      "Model saved to model_saves/model_epoch_14.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.40it/s, accuracy=17.82%, loss=0.0192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 completed. Loss: 0.0192, Accuracy: 17.82%\n",
      "Model saved to model_saves/model_epoch_15.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.43it/s, accuracy=17.80%, loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 completed. Loss: 0.0191, Accuracy: 17.80%\n",
      "Model saved to model_saves/model_epoch_16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.45it/s, accuracy=17.80%, loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 completed. Loss: 0.0191, Accuracy: 17.80%\n",
      "Model saved to model_saves/model_epoch_17.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.48it/s, accuracy=17.82%, loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 completed. Loss: 0.0191, Accuracy: 17.82%\n",
      "Model saved to model_saves/model_epoch_18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.48it/s, accuracy=17.77%, loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 completed. Loss: 0.0191, Accuracy: 17.77%\n",
      "Model saved to model_saves/model_epoch_19.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 3303/3303 [03:08<00:00, 17.54it/s, accuracy=17.80%, loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 completed. Loss: 0.0191, Accuracy: 17.80%\n",
      "Model saved to model_saves/model_epoch_20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.46it/s, accuracy=17.75%, loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 completed. Loss: 0.0191, Accuracy: 17.75%\n",
      "Model saved to model_saves/model_epoch_21.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 3303/3303 [03:10<00:00, 17.30it/s, accuracy=17.73%, loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 completed. Loss: 0.0191, Accuracy: 17.73%\n",
      "Model saved to model_saves/model_epoch_22.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 3303/3303 [03:11<00:00, 17.25it/s, accuracy=17.72%, loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 completed. Loss: 0.0191, Accuracy: 17.72%\n",
      "Model saved to model_saves/model_epoch_23.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.41it/s, accuracy=17.73%, loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 completed. Loss: 0.0191, Accuracy: 17.73%\n",
      "Model saved to model_saves/model_epoch_24.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 3303/3303 [03:09<00:00, 17.38it/s, accuracy=17.70%, loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 completed. Loss: 0.0191, Accuracy: 17.70%\n",
      "Model saved to model_saves/model_epoch_25.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 3303/3303 [03:10<00:00, 17.32it/s, accuracy=17.70%, loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 completed. Loss: 0.0191, Accuracy: 17.70%\n",
      "Model saved to model_saves/model_epoch_26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 3303/3303 [03:11<00:00, 17.28it/s, accuracy=17.75%, loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 completed. Loss: 0.0191, Accuracy: 17.75%\n",
      "Model saved to model_saves/model_epoch_27.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 3303/3303 [03:11<00:00, 17.23it/s, accuracy=17.72%, loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 completed. Loss: 0.0191, Accuracy: 17.72%\n",
      "Model saved to model_saves/model_epoch_28.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 3303/3303 [03:11<00:00, 17.27it/s, accuracy=17.67%, loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 completed. Loss: 0.0191, Accuracy: 17.67%\n",
      "Model saved to model_saves/model_epoch_29.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 3303/3303 [03:12<00:00, 17.18it/s, accuracy=17.65%, loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 completed. Loss: 0.0191, Accuracy: 17.65%\n",
      "Model saved to model_saves/model_epoch_30.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 3303/3303 [03:12<00:00, 17.16it/s, accuracy=17.69%, loss=0.0192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 completed. Loss: 0.0192, Accuracy: 17.69%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory model_saves does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/davidledbetter/NLP-673/GradAssesment/Model.ipynb Cell 15\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidledbetter/NLP-673/GradAssesment/Model.ipynb#X32sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m completed. Loss: \u001b[39m\u001b[39m{\u001b[39;00mavg_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Accuracy: \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidledbetter/NLP-673/GradAssesment/Model.ipynb#X32sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m save_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel_saves/model_epoch_\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.pth\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/davidledbetter/NLP-673/GradAssesment/Model.ipynb#X32sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m torch\u001b[39m.\u001b[39;49msave({\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidledbetter/NLP-673/GradAssesment/Model.ipynb#X32sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mepoch\u001b[39;49m\u001b[39m'\u001b[39;49m: epoch \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidledbetter/NLP-673/GradAssesment/Model.ipynb#X32sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mmodel_state_dict\u001b[39;49m\u001b[39m'\u001b[39;49m: model\u001b[39m.\u001b[39;49mstate_dict(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidledbetter/NLP-673/GradAssesment/Model.ipynb#X32sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39moptimizer_state_dict\u001b[39;49m\u001b[39m'\u001b[39;49m: optimizer\u001b[39m.\u001b[39;49mstate_dict(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidledbetter/NLP-673/GradAssesment/Model.ipynb#X32sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m'\u001b[39;49m: avg_loss,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidledbetter/NLP-673/GradAssesment/Model.ipynb#X32sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m: accuracy,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidledbetter/NLP-673/GradAssesment/Model.ipynb#X32sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m }, save_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidledbetter/NLP-673/GradAssesment/Model.ipynb#X32sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel saved to \u001b[39m\u001b[39m{\u001b[39;00msave_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/envs/tf/lib/python3.9/site-packages/torch/serialization.py:618\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    615\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    617\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 618\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    619\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    620\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/tf/lib/python3.9/site-packages/torch/serialization.py:492\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m     container \u001b[39m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 492\u001b[0m \u001b[39mreturn\u001b[39;00m container(name_or_buffer)\n",
      "File \u001b[0;32m~/miniconda/envs/tf/lib/python3.9/site-packages/torch/serialization.py:463\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39mPyTorchFileWriter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_stream))\n\u001b[1;32m    462\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mPyTorchFileWriter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory model_saves does not exist."
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 100\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "                        # Need a small learning rate for the sheer number of params\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "    \n",
    "    for inputs, targets in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        hidden_state = None  \n",
    "        predictions, _ = model(inputs, hidden_state)\n",
    "\n",
    "        loss = criterion(predictions.view(-1, word_vocab_size), targets.view(-1)).to(device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(predictions.data, -1)\n",
    "        total_correct += (predicted.view(-1) == targets.view(-1)).sum().item()\n",
    "        total_samples += targets.numel()\n",
    "\n",
    "        avg_loss = total_loss / total_samples\n",
    "        accuracy = total_correct / total_samples * 100\n",
    "        progress_bar.set_postfix(loss=avg_loss, accuracy=f'{accuracy:.2f}%')\n",
    "\n",
    "    print(f\"Epoch {epoch+1} completed. Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    save_path = f'model_saves/model_epoch_{epoch+1}.pth'\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy,\n",
    "    }, save_path)\n",
    "\n",
    "    print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_sequence_length = 50\n",
    "\n",
    "\n",
    "# train_predictors, train_targets = data_to_tensors(train_corpus, char_vocab, word_vocab, max_sequence_length, sequence_count)\n",
    "# valid_predictors, valid_targets = data_to_tensors(valid_corpus, char_vocab, word_vocab, max_sequence_length, sequence_count)\n",
    "# test_predictors, test_targets = data_to_tensors(test_corpus, char_vocab, word_vocab, max_sequence_length, sequence_count)\n",
    "\n",
    "# batch_size = 20\n",
    "# train_dataset = TensorDataset(train_predictors, train_targets)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # validation and test datasets\n",
    "# valid_dataset = TensorDataset(valid_predictors, valid_targets)\n",
    "# valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# test_dataset = TensorDataset(test_predictors, test_targets)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
